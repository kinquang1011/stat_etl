nameNode=hdfs://c408.hadoop.gda.lo:8020
jobTracker=jt.hadoop.gda.lo:8050
homeDir=/user/fairy/oozie/yentn2
hdfsHomeDir=${homeDir}/bundle
hdfsLogDir=/ge/warehouse
hdfsGameLog=/ge/gamelogs

oozie.use.system.libpath=false
action.sharelib.for.spark=spark
action.sharelib.for.sqoop=sqoop
#oozie.libpath=/apps/oozie/share/lib
oozie.libpath=/user/spark/share/lib/lib_20161117110230

toRecipients=mailforwarder+canhtq+quangctn+yentn2@vng.com.vn
alertContacts=mailforwarder+canhtq+quangctn+yentn2@vng.com.vn

group=etl
type=etl_hourly
kickOffTime=2017-02-01T001:30Z
startDate=2017-04-20T14:20Z
endDate=2020-09-09T01:30Z
bundleApplicationPath=${hdfsHomeDir}/${group}/${type}
libApplicationPath=${homeDir}/lib
oozie.bundle.application.path=${bundleApplicationPath}/bundle.xml

sparkOpts= --conf spark.yarn.queue=production --conf spark.executor.memory=3g --conf spark.driver.memory=3g  --conf spark.executor.cores=1 --conf spark.executor.instances=3 --conf spark.yarn.jars=hdfs://c408.hadoop.gda.lo:8020/user/fairy/libs/spark2/*.jar --conf spark.shuffle.memoryFraction=0.5 --conf spark.buffer.pageSize=2m --files hdfs:///user/spark/share/lib/lib_20161117110230/hive-site.xml,hdfs:///user/spark/share/lib/lib_20161117110230/spark-defaults.conf --properties-file ./spark-defaults.conf --jars hdfs:///user/spark/share/lib/lib_20161117110230/datanucleus-api-jdo-3.2.6.jar,hdfs:///user/spark/share/lib/lib_20161117110230/datanucleus-core-3.2.10.jar,hdfs:///user/spark/share/lib/lib_20161117110230/datanucleus-rdbms-3.2.9.jar 
