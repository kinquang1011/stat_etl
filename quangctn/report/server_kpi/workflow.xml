<workflow-app name="UB :: SPARK :: ${gameCode} - ${type} - ${logDate}" xmlns="uri:oozie:workflow:0.5" xmlns:sla="uri:oozie:sla:0.2">
    
    <global>
		<job-tracker>${jobTracker}</job-tracker>
       	<name-node>${nameNode}</name-node>
       	
       	<configuration>
            <property><name>mapreduce.job.queuename</name><value>production</value></property>
            <property><name>oozie.launcher.mapred.job.queue.name</name><value>interactive</value></property>
        </configuration>
    </global>

    <start to="kpi-report-step-1" />

    <!-- BEGIN MAIN PROCESSING -->
    <action name="kpi-report-step-1">
        <spark xmlns="uri:oozie:spark-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${sparkMaster}</master>
            <name>spark-${group}-${gameCode}-${type}-${logDate}</name>
            <class>${sparkClass}</class>
            <jar>${nameNode}${bundleApplicationPath}/lib/${statsSparkJar}</jar>
            <spark-opts>${sparkOpts}</spark-opts>

            <arg>game_code=${gameCode}</arg>
            <arg>log_date=${logDate}</arg>
            <arg>calc_id=${calcId}</arg>
            <arg>source=${source}</arg>
            <arg>group_id=${groupId}</arg>
            <arg>job_name=spark-${gameCode}-${type}-${logDate}</arg>

            <!-- Change Params -->
            <arg>report_number=${reportNumber}</arg>
            <arg>run_timing=${runTiming}</arg>
            <arg>log_dir=${hdfsLogDir}</arg>
        </spark>
        <ok to="kpi-report-step-2"/>
        <error to="alert-error"/>
    </action>

    <action name="kpi-report-step-2">
        <spark xmlns="uri:oozie:spark-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${sparkMaster}</master>
            <name>spark-${group}-${gameCode}-${type}-${logDate}</name>
            <class>${sparkClass}</class>
            <jar>${nameNode}${bundleApplicationPath}/lib/${statsSparkJar}</jar>
            <spark-opts>${sparkOpts}</spark-opts>

            <arg>game_code=${gameCode}</arg>
            <arg>log_date=${logDate}</arg>
            <arg>calc_id=${calcId}</arg>
            <arg>source=${source}</arg>
            <arg>group_id=${groupId}</arg>

            <arg>job_name=spark-${group}-${gameCode}-${type}-${logDate}</arg>

            <!-- Change Params -->
            <arg>report_number=${reportNumber}</arg>
            <arg>run_timing=ac30,a3,a14</arg>
            <arg>log_dir=${hdfsLogDir}</arg>
        </spark>
        <ok to="end"/>
        <error to="alert-error"/>
    </action>
    <!-- END MAIN PROCESSING -->

    <action name="alert-error">
        <email xmlns="uri:oozie:email-action:0.1">
            <to>${toRecipients}</to>
            <subject>WORKFLOW FAILED :::: ${wf:name()}</subject>
            <body>
LOG DATE: ${logDate}
            
NAME: ${wf:name()}
USER RETENTION
ID: ${wf:id()}

ERROR MESSAGE: [${wf:errorMessage(wf:lastErrorNode())}]
            </body>
        </email>
        <ok to="kill"/>
        <error to="kill"/>
	</action>
	
    <kill name="kill">
        <message>UB :: VDP :: ${group} -${gameCode} - ${type} - workflow fail</message>
    </kill>
    <end name="end"/>
</workflow-app>

